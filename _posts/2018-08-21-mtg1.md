---
layout: post
title:  "Meeting 1: 'Algorithm'"
date:   2018-08-21 11:56:15 -0400
categories: into
---

* Jeanne - French Dept, 1st yr PhD
* Reid - Fiction major, 1st yr PhD
* Oscar - CS Dept, generative modeling
* Audrey - French, musicology
* Liz - Chemistry, 6th yr PhD
* Veronica - Chem Eng, MS
* Paula - historical music
* Eamonn - Music, 6th yr PhD




**Theme I**: What’s the difference between algorithm generated art and pre-computer artwork?

**Theme II**: Recursion in algorithm generated art vs. pre-computer artwork


//

**Eamonn**:
Reading 1+2 are approaching the definition ‘algorithm’ in two ways; culture is also an important word.

**Katy**:
Reading 3 was selected to capture the hype around machine learning.


//

**Reid**:
Question on neural network: does it copy every character and adjust probability afterwards?

**Oscar**:
Select the model, often problem dependent. Use specific loss function to achieve minimal loss, but also not to overfit e.g. only training on one specific breed of cat, instead of a good generalization.

**Veronica**:
Does sample size matter w.r.t. Overfitting?

**O’s answer**: yup, you want to capture the whole of it

**Katy**:
ML feels impenetrable, while Sol Le Witt's wall drawing instructions feel extremely simple. What do you feel is the difference between the two?

**Liz**: (answering to Katy)
Where is the artist locating themselves: do they invite participation? e.g. heart piece (performance - improv could happen, and open ended; and layman can. 

**Eamonn**:
Sol Le Witt instructions are written in natural language, so it's easy to perceive by layman, and you’d be able to participate -- machine learning doesn’t necessarily enable that, since you would need to have expertise.


Generating artwork via computer shouldn’t be exclusive to people who’s proficient with it; doesn’t mean that work generated by computer isn’t participatory.
We can’t really say how the training samples are going to affect the results.

**Veronica**:
Transparency of the process in ‘pure’ arts
Whilst in algorithmic culture ('look what Amazon is doing, how dare they'), laymen of CS or ML wouldn’t be able to create.
Whilst you have this connection with painting.

**Oscar**:
Algorithms are fundamentally not creative; whereas revisiting poetry or music could open new possibilities; algorithms have problem ‘generating’ or ‘creating’, it’s actually the human being behind it that’s thinking about new problems.
Algorithms are simply solving it.

//

**Katy**:
The definition of ‘creativity’.
What’s the criteria?
She says that algorithms can surprise us, but not necessarily consistently.

**Veronica + Oscar**:
Open-endedness is more there, in actual creative process.
Doing math/research, is creative.
Whilst algorithms can suffice up to certain points, but not beyond it; it would only work to the point the human being instructs it to do.

**Katy + Oscar**:
novelty search helps to find different niches (used novelty algorithms to train walkers), using the algorithm to optimize different objectives. There might be certain solutions that are suboptimal yet you’re stuck in, with different niches, you’ll be able to get out of the local minima (or reach local maxima??)

**Veronica**:
What is the objective function?

**Katy**:
Something about correctness (computing vs ..??)

**Liz**:
What’s the definition of culture exactly?
Her take: Human expression that involves activities + Distinctive ways of life.
Yet in case of the Amazon case, algorithm generated answers.
What’s the definition of computer? It has a method and it has an end.

**Katy**:
If the algorithm is too slow then it’s not going to be useful.
Efficiency over accuracy.

**Oscar**:
Do you think humans have objective function and the need to fulfill something?

**Eamonn**:
(Answering to Oscar)
Loss vs. objective function. It’s important that you involve in the quantitative aspect to it when thinking about issues as such. We do have objectives in life, yet it’s hard (yet not impossible) to put a number to it.

Whilst algorithms could potentially quantify it; f humans are actually an algorithm
we would constantly reflecting on the work + empirically adjusting for it.
Not waking up in the morning and actually quantify if today’s going to be ‘5 times harder’ (or earn 5 times more salary).

**Veronica**:
From the readers’ perspective, you could interpret it differently than the writers could initially intend.

**Reid**:
If you have a random block of words, you could read emotion and meaning to it: which is creativity of itself. Meaning is still there regardless of whether it’s a qualified one. As long as you respond to it with a creative act (interpreting it in your own way).

//

**Eamonn**:
Truth is somewhere in the middle. It’s not necessarily the ‘Amazon people’, but rather something in between. Algorithms could take one error and magnify it; Sol’s painting cannot be mass produced, whilst algorithms can.

**Paula**:
I'm allergic to the idea of efficiency (separates arts from things that could potentially be bad).
e.g. some piece of music isn’t efficient at all, and there wasn’t the goal of making it efficient.

**Reid**:
(in response to Paula) 
Efficiency in corporate sense really stems from a practical sense (defending ‘efficiency’)

**Katy**:
(in response to Paula)
Writing novels real fast; could be pulp fiction. 

**Jeanne**:
Discomfort with things that is completely created by machine.
More comfortable w/ pre-computer algorithms.
Human is still the real creator, whilst algorithms are not.

**Audrey**:
It’s really interesting to think about who is the actual author of this piece of art.
Human or algorithm?
Who thinks that and why do they think that.

**Liz**:
More physical effort involved w/ ‘pure’ art.
Whilst w/ algorithms, it’s just ‘pressing the button’.

**Jeanne**:
Writers + scientists group.
Came up w/ constraints to create literal things.
A writer wrote the entire book w/o letter ‘E’. 10 sonnets, all have the same rhyme in the end (hundred thousand billion poems).

//


**Linbi**:
Who’s the actual creator?
Code is also created by human. 
Physical vs. intellectual effort - on Liz’s point. Brain as a computational model (so in that sense also algorithmic).

//

**Veronica**:
Conscience vs. algorithms.
If you could model the brain as the machine, then what’s the distinction between the two then?
In some sense we’re efficient machines.
Whilst for computers,
the time to spit out shitty Shakespeare could be the six month of painful writing for them.

**Reid**:
Recursion.
You could start w/ something random, and you’d go back at them, then you’ll go forward, but it’ll be back to the recurring theme again.
Will distribute the article.

**Liz**:
Less developed writers write one draft and they’ll be done.
Whilst matured writer would go back to the draft and modify again, being recursive.

**Paula**:
Music notation sometimes are viewed as algorithmic adjacent.

**Eamonn**:
Maybe we can talk about recursion.
Recursion is not just the repetition of different things, it’s the opportunity to reflect ourselves
(Katy joined in:) 
It’s also different than feedback.

**Liz**:
Q: how would you describe the neural network, since the word recursive is also mentioned there?

**Katy**:
(Answering to Liz)
Explaining neural networks on the board.
Recursiveness could happen.

**Veronica**:
For reading 3 - What’s the assumption that ‘the shakespeare example’ made in order to make it work?
(Answering to Eamonn:) 
Input and output layer are representations of the alphabet, and that’s it.
There’s still assumption that certain letter would precede or follow another one simply based on past literature.

**Liz**:
‘Cause you didn’t program any grammar in, you simply have the prior in and the algorithm would generate it.

**Eamonn**:
‘The evolution of samples while training’.
You put letters in and grammar came out.
When the algorithm is young, it makes no sense; yet as it ages, the output actually starts to make sense.

**Audrey**:
Q - Where does ‘natural language’ come from?

**Katy**:
(Answering to Audrey) could be from information theory

//

**Eamonn**:
Spin off on Reading 3’s example (wikipedia + code). Rhetoric of the article: Why do you think he’s chosen wikipedia + code + shakespeare as examples? ‘Cause you could potentially choose other things.

**Katy**:
(Answering to Eamonn) 
‘Cause that’s the things that worked really well.

**Veronica**:
(Answering to Eamonn)
Trying to produce a true statement.
Whereas in C, Linux, it could be more logical; and it tend to fail.

**Reid**:
(Answering to Eamonn) 
Read it as different format, and it even put brackets in the right spot.

**Eamonn**:
(Answering to himself)
‘Cause you have really large datasets and you could potentially train them.

**Veronica**:
(Answering to Eamonn again)
He’s becoming more and more radical, and it’s the brand new perspective.

**Eamonn**: 
(Remarking on the colorful rows at the end)
What is thinking about, since there’s high activation in one neuron.

**Eamonn**:
Other attempts on music. Sounded pretty bad (Paula concurs). Goldberg’s approach on grammar. Question is:
Do you tell the algorithm what we already know about the grammar? Or you have them figure it out themselves?

**Katy**:
The computational ppl kicked the linguists out; but now ppl are thinking of bringing the linguists in again. On what aspect of the expertise they should be using.

**Paula**:
One partiata that was actually inspired by Sol’s painting.


